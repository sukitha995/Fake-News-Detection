# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MIk3N9C1gy7jkdZXznGE2G7cszTuUmnD
"""

# ===============================
# Fake News Detection - Full Script
# ===============================

# Step 0: Imports
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, roc_curve, auc
)

# Step 1: Load CSVs
fake = pd.read_csv("/Fake.csv")
true = pd.read_csv("/True.csv")

fake["class"] = 0   # Fake = 0
true["class"] = 1   # True = 1

# Merge & shuffle
df = pd.concat([fake, true], axis=0).reset_index(drop=True)
df = df.sample(frac=1, random_state=42).reset_index(drop=True)

# Step 2: Split
x = df["text"]
y = df["class"]

x_train, x_test, y_train, y_test = train_test_split(
    x, y, test_size=0.25, random_state=42
)

# TF-IDF Vectorization
vectorizer = TfidfVectorizer(stop_words="english", max_df=0.7)
x_train_vec = vectorizer.fit_transform(x_train)
x_test_vec = vectorizer.transform(x_test)

# Step 3: Train Models
models = {
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "Decision Tree": DecisionTreeClassifier(),
    "Random Forest": RandomForestClassifier(n_estimators=100),
    "Naive Bayes": MultinomialNB()
}

results = {}
for name, model in models.items():
    model.fit(x_train_vec, y_train)
    y_pred = model.predict(x_test_vec)
    results[name] = {
        "Accuracy": accuracy_score(y_test, y_pred),
        "Precision": precision_score(y_test, y_pred),
        "Recall": recall_score(y_test, y_pred),
        "F1-Score": f1_score(y_test, y_pred),
        "Confusion": confusion_matrix(y_test, y_pred)
    }

# Step 4: Results Table & Bar Chart
metrics_df = pd.DataFrame(results).T.drop(columns=["Confusion"])
print("\n=== Model Performance Table ===")
print(metrics_df)

metrics_df.plot(kind="bar", figsize=(10,6))
plt.title("Model Performance Comparison")
plt.xticks(rotation=45)
plt.ylabel("Score")
plt.show()

# Step 5: Feature-Level Insights
feature_names = vectorizer.get_feature_names_out()

# Logistic Regression coefficients
log_reg = models["Logistic Regression"]
coefs = log_reg.coef_[0]

# Top indicative words
top_pos = np.argsort(coefs)[-20:]  # True
top_neg = np.argsort(coefs)[:20]   # Fake

print("\nTop words for TRUE news:", [feature_names[i] for i in top_pos])
print("Top words for FAKE news:", [feature_names[i] for i in top_neg])

# Plot top TRUE words
plt.figure(figsize=(10,6))
sns.barplot(x=coefs[top_pos], y=[feature_names[i] for i in top_pos])
plt.title("Top 20 words indicating TRUE news (Logistic Regression)")
plt.show()

# Plot top FAKE words
plt.figure(figsize=(10,6))
sns.barplot(x=coefs[top_neg], y=[feature_names[i] for i in top_neg])
plt.title("Top 20 words indicating FAKE news (Logistic Regression)")
plt.show()

# Random Forest Feature Importance
rf = models["Random Forest"]
importances = rf.feature_importances_
indices = np.argsort(importances)[-20:]

plt.figure(figsize=(10,6))
sns.barplot(x=importances[indices], y=[feature_names[i] for i in indices])
plt.title("Top 20 Important Features (Random Forest)")
plt.show()

# Step 6: Confusion Matrices
for name, res in results.items():
    cm = res["Confusion"]
    plt.figure(figsize=(5,4))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
                xticklabels=["Fake","True"], yticklabels=["Fake","True"])
    plt.title(f"Confusion Matrix - {name}")
    plt.ylabel("Actual")
    plt.xlabel("Predicted")
    plt.show()

# Step 7: ROC Curves & AUC
plt.figure(figsize=(8,6))

for name, model in models.items():
    if hasattr(model, "predict_proba"):
        y_prob = model.predict_proba(x_test_vec)[:,1]
    else:
        y_prob = model.decision_function(x_test_vec)

    fpr, tpr, _ = roc_curve(y_test, y_prob)
    auc_score = auc(fpr, tpr)
    plt.plot(fpr, tpr, label=f"{name} (AUC={auc_score:.2f})")

plt.plot([0,1],[0,1],"k--")
plt.title("ROC Curves")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend()
plt.show()

# Step 8: WordClouds
fake_text = " ".join(fake["text"])
true_text = " ".join(true["text"])

plt.figure(figsize=(12,6))
wc_fake = WordCloud(width=800, height=400, background_color="black").generate(fake_text)
wc_true = WordCloud(width=800, height=400, background_color="white").generate(true_text)

plt.subplot(1,2,1)
plt.imshow(wc_fake, interpolation="bilinear")
plt.axis("off")
plt.title("Fake News WordCloud")

plt.subplot(1,2,2)
plt.imshow(wc_true, interpolation="bilinear")
plt.axis("off")
plt.title("True News WordCloud")

plt.show()